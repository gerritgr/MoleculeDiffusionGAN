{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/MoleculeDiffusionGAN/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovmM6MKh0RHG"
      },
      "source": [
        "# ðŸ’ŠðŸŒ€ MoleculeDiffusionGAN ðŸŒ€ðŸ’Š"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXB58ofd0yX-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is used for the naming of files and folders\n",
        "PROJECT_NAME = \"MoldDiffGAN\"\n",
        "PATH_PATTERN_BASE = \"moldiffgan1\"\n",
        "PATH_PATTERN = PATH_PATTERN_BASE\n",
        "\n",
        "# Setting BASELINE to True would deactivate the discriminator.\n",
        "BASELINE = False\n",
        "DEBUG = False\n"
      ],
      "metadata": {
        "id": "gCcXEAS_7brw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yIsuEC808hb"
      },
      "source": [
        "### Handle Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX4PHxg-00D1"
      },
      "source": [
        "On Colab, we need to install some additional packages.\n",
        "If running on Colab, we use Google Drive to store results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Check for Google Colab and WandB\n",
        "USE_COLAB = False\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  USE_COLAB = True\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  import wandb # need to do this before chaning CWD\n",
        "except:\n",
        "  os.system(\"pip install wandb\")\n",
        "\n",
        "# Load Google Drive\n",
        "if USE_COLAB:\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "  dir_path = f'/content/drive/MyDrive/colab/{PROJECT_NAME}/'\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  print(\"Current Working Directory: \", os.getcwd())\n",
        "  if os.getcwd() != dir_path:\n",
        "    os.chdir(dir_path)\n",
        "    print(\"New Working Directory: \", os.getcwd())\n",
        "\n",
        "\n",
        "torch_version = torch.__version__.split(\"+\")\n",
        "try:\n",
        "  import torch_geometric\n",
        "except:\n",
        "  os.system(\"pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\")\n",
        "  os.system(\"pip install torch-geometric\")\n",
        "\n",
        "try:\n",
        "  import rdkit\n",
        "except:\n",
        "  os.system(\"pip install rdkit\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6wrjwx9vQmH",
        "outputId": "9427bc1e-7aa4-400f-9d76-1fa820feccd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Current Working Directory:  /content\n",
            "New Working Directory:  /content/drive/MyDrive/colab/MoldDiffGAN_run1debug\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceqoOXap7kBb"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#from PIL import Image\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import traceback\n",
        "import time\n",
        "import copy\n",
        "import pickle\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import gzip\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Sequential as Seq\n",
        "from torch.nn import Linear as Lin\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import (\n",
        "    PNA,\n",
        "    GATv2Conv,\n",
        "    GraphNorm,\n",
        "    BatchNorm,\n",
        "    global_mean_pool,\n",
        "    global_add_pool\n",
        ")\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx, degree\n",
        "\n",
        "\n",
        "# Setting DPI for image quality\n",
        "plt.rcParams['figure.dpi'] = 100  # Set this to 300 to get better image quality\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "lnxsm_Qm8QQ4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d6k-s1v37muv"
      },
      "outputs": [],
      "source": [
        "# Load code to convert molecules to pyg tensors if using Colab\n",
        "if USE_COLAB and not os.path.exists(\"smiles_to_pyg\"):\n",
        "  os.system(\"git clone https://github.com/gerritgr/MoleculeDiffusionGAN.git && cp -R MoleculeDiffusionGAN/* .\")\n",
        "\n",
        "from smiles_to_pyg.molecule_load_and_convert import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2oEPNiw_utN"
      },
      "source": [
        "## Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "## Diffusion\n",
        "##\n",
        "TIMESTEPS = 1000\n",
        "START = 0.0001\n",
        "END = 0.015\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 256\n",
        "GAMMA = 0.1\n",
        "\n",
        "##\n",
        "## Prediction/Denoising\n",
        "##\n",
        "LEARNING_RATE_GEN = 0.001\n",
        "EPOCHS_GEN = 60\n",
        "\n",
        "# PNA Pred\n",
        "DROPOUT_PRED = 0.05\n",
        "DEPTH_PRED = 4\n",
        "HIDDEN_CHANNELS_PRED = 32\n",
        "TOWERS_PRED = 1\n",
        "NORMALIZATION_PRED = True\n",
        "\n",
        "##\n",
        "## Discriminator\n",
        "##\n",
        "EPOCHS_DISC_MODEL = 70\n",
        "DISC_NOISE = 0.3\n",
        "\n",
        "# PNA Disc\n",
        "HIDDEN_CHANNELS_DISC = 8\n",
        "DEPTH_DISC = 4\n",
        "DROPOUT_DISC = 0.03\n",
        "NORMALIZATION_DISC = True\n",
        "\n",
        "##\n",
        "## Molecule Encoding\n",
        "##\n",
        "INDICATOR_FEATURE_DIM = 1\n",
        "FEATURE_DIM = 5  # (has to be the same for atom and bond)\n",
        "ATOM_FEATURE_DIM = FEATURE_DIM\n",
        "BOND_FEATURE_DIM = FEATURE_DIM\n",
        "NON_NODES = [True] + [False] * 5 + [True] * 5\n",
        "NON_EDGES = [True] + [True] * 5 + [False] * 5\n",
        "\n",
        "TIME_FEATURE_DIM = 1\n"
      ],
      "metadata": {
        "id": "BpeBwAGC91Xu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9vsl3np_y0I"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log(d):\n",
        "  try:\n",
        "    import wandb\n",
        "    wandb.log(d)\n",
        "  except:\n",
        "    print(d)\n",
        "\n",
        "\n",
        "def load_file(filepath):\n",
        "  print(\"Trying to read\", filepath)\n",
        "  try:\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "      return pickle.load(f)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "def write_file(filepath, data):\n",
        "  try:\n",
        "    data = data.cpu()\n",
        "  except:\n",
        "    pass\n",
        "  print(\"Trying to write\", filepath)\n",
        "  with gzip.open(filepath, 'wb') as f:\n",
        "    pickle.dump(data, f)\n"
      ],
      "metadata": {
        "id": "8vbsdmdl-JFm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(seed=1234):\n",
        "  try:\n",
        "    dataset_train, dataset_test = load_file('dataset.pickle')\n",
        "    if DEBUG:\n",
        "      return dataset_train[:len(dataset_train) // 10], dataset_test[:len(dataset_test) // 10]\n",
        "    return dataset_train, dataset_test\n",
        "  except Exception as e:\n",
        "    print(f\"Could not load dataset due to error: {str(e)}, generate it now\")\n",
        "\n",
        "  dataset = read_qm9()\n",
        "  dataset_all = [g for g in dataset if g.x.shape[0] > 1]\n",
        "  dataset = list()\n",
        "\n",
        "  for g in tqdm(dataset_all):\n",
        "    try:\n",
        "      assert \"None\" not in str(pyg_to_smiles(g))\n",
        "      dataset.append(g)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  print(f\"Built and cleaned dataset, length is {len(dataset)}, old length was {len(dataset_all)}\")\n",
        "  random.Random(seed).shuffle(dataset)\n",
        "  split = int(len(dataset) * 0.8 + 0.5)\n",
        "  dataset_train = dataset[:split]\n",
        "  dataset_test = dataset[split:]\n",
        "  assert(dataset_train[0].x[0, :].numel() == INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM)\n",
        "\n",
        "  write_file(\"dataset.pickle\", (dataset_train, dataset_test))\n",
        "  return dataset_train, dataset_test\n"
      ],
      "metadata": {
        "id": "QaL_PWZH-eiM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aQlj5MPz_4PB"
      },
      "outputs": [],
      "source": [
        "def generate_schedule(start = START, end = END, timesteps=TIMESTEPS):\n",
        "  \"\"\"\n",
        "  Generates a schedule of beta and alpha values for a forward process.\n",
        "\n",
        "  Args:\n",
        "  start (float): The starting value for the beta values. Default is START.\n",
        "  end (float): The ending value for the beta values. Default is END.\n",
        "  timesteps (int): The number of timesteps to generate. Default is TIMESTEPS.\n",
        "\n",
        "  Returns:\n",
        "  tuple: A tuple of three tensors containing the beta values, alpha values, and\n",
        "  cumulative alpha values (alpha bars).\n",
        "  \"\"\"\n",
        "  betas = torch.linspace(start, end, timesteps, device = DEVICE)\n",
        "  assert(betas.numel() == TIMESTEPS)\n",
        "  return betas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MZJBlO6C_7-x"
      },
      "outputs": [],
      "source": [
        "def visualize_smiles_from_file(filepath):\n",
        "    # Read SMILES from file\n",
        "    with open(filepath, 'r') as file:\n",
        "        smiles_list = [line.split(\"'\")[1] for line in file.readlines() if \"'\" in line]\n",
        "\n",
        "    # Convert SMILES to RDKit Mol objects, filtering out invalid ones\n",
        "    mols = [Chem.MolFromSmiles(smile) for smile in smiles_list[:100]]\n",
        "    mols = [mol for mol in mols if mol is not None]\n",
        "\n",
        "    # Determine grid size\n",
        "    num_mols = len(mols)\n",
        "    cols = 10\n",
        "    rows = min(10, -(-num_mols // cols))  # ceil division\n",
        "\n",
        "    # Create a subplot grid\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(20, 20),\n",
        "                            gridspec_kw={'wspace': 0.3, 'hspace': 0.3})\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            ax = axs[i, j]\n",
        "            ax.axis(\"off\")  # hide axis\n",
        "            idx = i * cols + j  # index in mols list\n",
        "            if idx < num_mols:\n",
        "                img = Draw.MolToImage(mols[idx], size=(200, 200))\n",
        "                ax.imshow(img)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig(filepath + '.jpg', format='jpg', bbox_inches='tight')\n",
        "    plt.close(fig)  # Close the figure after saving to free up memory\n",
        "    try:\n",
        "        time.sleep(0.01)\n",
        "        wandb.log_artifact(filepath + '.jpg', name=f\"jpg_{SWEEP_ID}_{filepath.replace('.','')}\", type=\"smiles_grid_graph\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pred_from_noise(noise_pred, x_with_noise, future_t):\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(1.0 - alphabar_t)\n",
        "  x_without_noise = x_with_noise - scaled_noise * noise_pred\n",
        "  x_without_noise = x_without_noise / torch.sqrt(alphabar_t)\n",
        "  return x_without_noise\n",
        "\n",
        "\n",
        "def get_noise_from_pred(original_pred, x_with_noise, future_t):\n",
        "  row_num = x_with_noise.shape[0]\n",
        "  betas = generate_schedule()\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "\n",
        "  scaled_noise = torch.sqrt(alphabar_t)\n",
        "  noise = x_with_noise - scaled_noise * original_pred\n",
        "  noise = noise / torch.sqrt(1.0 - alphabar_t)\n",
        "\n",
        "  return noise\n"
      ],
      "metadata": {
        "id": "X5qDfWWc_FJX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_smiles(smiles, filename):\n",
        "  try:\n",
        "    with open(filename, \"w\") as file:\n",
        "      for string in smiles:\n",
        "        file.write(str(string) + \"\\n\")\n",
        "\n",
        "    try:\n",
        "      wandb.log_artifact(filename, name=f\"src_txt_{SWEEP_ID}_{filename}\", type=\"smiles\")\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "    time.sleep(0.01)\n",
        "    visualize_smiles_from_file(filename)\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred during training: \\n\", str(e))\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "id": "WvP1-Zdg_mQC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04wgZXHaDUwG"
      },
      "source": [
        "## Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GfqAxJ2bDWxr"
      },
      "outputs": [],
      "source": [
        "def forward_diffusion(node_features, future_t):\n",
        "  \"\"\"\n",
        "  Performs a forward diffusion process on an node_features tensor.\n",
        "  Each row can theoreetically have its own future time point.\n",
        "  Implements the second equation from https://youtu.be/a4Yfz2FxXiY?t=649\n",
        "  \"\"\"\n",
        "  row_num = node_features.shape[0]\n",
        "\n",
        "  if \"class 'int'\" in str(type(future_t)) or \"class 'float'\" in str(type(future_t)):\n",
        "    future_t = torch.tensor([int(future_t)] * row_num).to(DEVICE)\n",
        "\n",
        "  feature_dim = node_features.shape[1]\n",
        "  future_t = future_t.view(-1)\n",
        "  assert(row_num == future_t.numel())\n",
        "  assert(future_t[0] == future_t[1]) # Let's assume they belong to the same graph.\n",
        "\n",
        "  betas = generate_schedule()\n",
        "\n",
        "  noise = torch.randn_like(node_features, device=DEVICE)\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphabar_t = torch.gather(alphas_cumprod, 0, future_t).view(row_num, 1)\n",
        "  assert(alphabar_t.numel() == row_num)\n",
        "\n",
        "  new_node_features_mean = torch.sqrt(alphabar_t) * node_features # Column-wise multiplication, now it is a matrix\n",
        "  assert(new_node_features_mean.shape == node_features.shape)\n",
        "  new_node_features_std = torch.sqrt(1.-alphabar_t) # This is a col. vector\n",
        "  new_node_features_std = new_node_features_std.repeat(1,feature_dim) # This is a matrix\n",
        "  assert(new_node_features_mean.shape == new_node_features_std.shape)\n",
        "  noisey_node_features =  new_node_features_mean + new_node_features_std * noise\n",
        "\n",
        "  return noisey_node_features, noise\n",
        "\n",
        "#forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([0,0,999], device=DEVICE)), print(\"\"), forward_diffusion(torch.tensor([1,2,3.], device=DEVICE).view(3,1), torch.tensor([999,999,999], device=DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2BUMzmPA6-W"
      },
      "source": [
        "## Denoising NN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_to_degree_bin(train_dataset):\n",
        "  \"\"\"\n",
        "  Convert a dataset to a histogram of node degrees (in-degrees).\n",
        "  Load from file if available; otherwise, compute from the dataset.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Attempt to load the degree histogram from a file.\n",
        "    deg = load_file('deg.pickle')\n",
        "    deg = deg.to(DEVICE)\n",
        "    return deg\n",
        "  except Exception as e:\n",
        "    print(f\"Could not find degree bin due to error: {str(e)}, generate it now\")\n",
        "\n",
        "  # Assert that the dataset is provided.\n",
        "  assert(train_dataset is not None)\n",
        "\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  # Create an empty histogram for degrees.\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "  # Populate the histogram with data from the dataset.\n",
        "  for data in train_dataset:\n",
        "    data = data.to(DEVICE)\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "\n",
        "  # Save the computed histogram to a file.\n",
        "  write_file(\"deg.pickle\", deg.cpu())\n",
        "\n",
        "  return deg\n"
      ],
      "metadata": {
        "id": "I78sdWNKNJL1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=HIDDEN_CHANNELS_PRED, depth=DEPTH_PRED, dropout=DROPOUT_PRED, towers=TOWERS_PRED, normalization=NORMALIZATION_PRED, pre_post_layers=1):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Adjust hidden channels for the given towers.\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1) # must match\n",
        "\n",
        "    # Calculate input and output channels.\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM + TIME_FEATURE_DIM\n",
        "    out_channels = FEATURE_DIM\n",
        "\n",
        "    # Get degree histogram for the dataset\n",
        "    deg = dataset_to_degree_bin(train_dataset)\n",
        "\n",
        "    # Set aggregators and scalers for the PNA layer.\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "\n",
        "    # Create a normalization layer if required.\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "\n",
        "    # Define the PNA layer.\n",
        "    self.pnanet = PNA(\n",
        "        in_channels=in_channels,\n",
        "        hidden_channels=hidden_channels,\n",
        "        out_channels=hidden_channels,\n",
        "        num_layers=depth,\n",
        "        aggregators=aggregators,\n",
        "        scalers=scalers,\n",
        "        deg=deg,\n",
        "        dropout=dropout,\n",
        "        towers=towers,\n",
        "        norm=self.normalization,\n",
        "        pre_layers=pre_post_layers,\n",
        "        post_layers=pre_post_layers\n",
        "    )\n",
        "\n",
        "    # Define the final MLP layer.\n",
        "    self.final_mlp = Seq(\n",
        "        Lin(hidden_channels, hidden_channels),\n",
        "        nn.ReLU(),\n",
        "        Lin(hidden_channels, hidden_channels),\n",
        "        nn.ReLU(),\n",
        "        Lin(hidden_channels, out_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self, x_in, t, edge_index):\n",
        "    \"\"\"\n",
        "    Perform a forward pass through the PNAnet.\n",
        "    \"\"\"\n",
        "    row_num = x_in.shape[0]\n",
        "    t = t.view(-1, TIME_FEATURE_DIM)\n",
        "    x = torch.concat((x_in, t), dim=1)\n",
        "\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = self.final_mlp(x)\n",
        "\n",
        "    # Assertions for sanity checks\n",
        "    assert(x.numel() > 1)\n",
        "    assert(x.shape[0] == row_num)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "270vRkHbNYB6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_latest_checkpoint(model, optimizer, loss_list, epoch_i, path_pattern_checkpoint=None):\n",
        "  \"\"\"\n",
        "  Load the latest checkpoint from the disk.\n",
        "  \"\"\"\n",
        "  if path_pattern_checkpoint is None:\n",
        "    path_pattern_checkpoint = PATH_PATTERN + \"_model_epoch_*.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint_paths = sorted(glob.glob(path_pattern_checkpoint))\n",
        "    if len(checkpoint_paths) == 0:\n",
        "      return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "    latest_checkpoint_path = checkpoint_paths[-1]\n",
        "    checkpoint = torch.load(latest_checkpoint_path, map_location=DEVICE)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch_i = checkpoint['epoch']\n",
        "    loss_list = checkpoint['loss_list']\n",
        "\n",
        "    print(f\"Loaded checkpoint of epoch {epoch_i:08} from disk.\")\n",
        "  except Exception as e:\n",
        "    print(f\"Failed to load checkpoint. Error: {str(e)}\")\n",
        "\n",
        "  return model, optimizer, loss_list, epoch_i\n",
        "\n",
        "def save_model(model, optimizer, loss_list, epoch_i, upload=False):\n",
        "  \"\"\"\n",
        "  Save the model state to the disk.\n",
        "  \"\"\"\n",
        "  if epoch_i == 0: # Relevant for load_base_model()\n",
        "    return\n",
        "\n",
        "  save_path = f\"{PATH_PATTERN}_model_epoch_{epoch_i:08}.pth\" # Will do lexicographical ordering to load.\n",
        "\n",
        "  # Save the model and optimizer state dicts in a dictionary.\n",
        "  torch.save({\n",
        "    'epoch': epoch_i,\n",
        "    'loss_list': loss_list,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "  }, save_path)\n",
        "\n",
        "  if upload:\n",
        "    try:\n",
        "      wandb.log_artifact(save_path, name=f\"weights_{SWEEP_ID}_{epoch_i:08}_weightfile\", type=\"weight\")\n",
        "    except Exception as e:\n",
        "      print(f\"Failed to upload model. Error: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "G2EDh-9vXPrr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jGUISrgECQ-e"
      },
      "outputs": [],
      "source": [
        "def load_base_model(dataset_train, path_pattern=None):\n",
        "  model_base = PNAnet(dataset_train)\n",
        "  model_base = model_base.to(DEVICE)\n",
        "  loss_list = None\n",
        "  optimizer = Adam(model_base.parameters(), lr = LEARNING_RATE_GEN)\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0, path_pattern_checkpoint=path_pattern)\n",
        "\n",
        "  return model_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc7iJLKJCv3s"
      },
      "source": [
        "## Inference / Reverse Process"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise_one_step(model, g, i):\n",
        "  \"\"\"\n",
        "  Performs one step of denoising using the provided model.\n",
        "  \"\"\"\n",
        "  row_num = g.x.shape[0]\n",
        "\n",
        "  # Generate and calculate betas, alphas, and related parameters\n",
        "  betas = generate_schedule()\n",
        "  t = TIMESTEPS - i - 1  # i=0 indicates full noise\n",
        "  beta_t = betas[t]\n",
        "  alphas = 1. - betas\n",
        "  alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "  alphas_cumprod_t = alphas_cumprod[t]\n",
        "  sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1. - alphas_cumprod_t)\n",
        "  sqrt_recip_alphas_t = torch.sqrt(1.0 / alphas[t])\n",
        "  alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "\n",
        "  # Create the mask\n",
        "  mask = torch.concat(\n",
        "      (torch.tensor([False] * g.x_old.shape[0], device=DEVICE).view(-1, 1),\n",
        "       g.x_old[:, 1:] > -0.5),\n",
        "      dim=1\n",
        "  )\n",
        "\n",
        "  # Define future_t for the model predictions\n",
        "  future_t = torch.tensor([float(t)] * g.x.shape[0], device=DEVICE).view(-1, 1)\n",
        "  original_pred = model(g.x, future_t, g.edge_index)\n",
        "\n",
        "  # Extract noisy values and predict noise\n",
        "  x_with_noise = g.x[mask].view(row_num, -1)\n",
        "  future_t = torch.tensor([int(t)] * g.x.shape[0], device=DEVICE).view(-1)\n",
        "  noise_pred = get_noise_from_pred(original_pred, x_with_noise, future_t)\n",
        "\n",
        "  # Set endpoints values\n",
        "  values_now = g.x[mask].view(row_num, -1)\n",
        "  values_endpoint = noise_pred.view(row_num, -1)\n",
        "  assert values_now.shape == values_endpoint.shape\n",
        "\n",
        "  # Compute denoised values\n",
        "  model_mean = sqrt_recip_alphas_t * (values_now - beta_t * values_endpoint / sqrt_one_minus_alphas_cumprod_t)\n",
        "  values_one_step_denoised = model_mean  # in case that t == 0\n",
        "\n",
        "  if t != 0:\n",
        "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)  # in the paper this is in 3.2. Note that sigma^2 is variance, not std.\n",
        "    posterior_std_t = torch.sqrt(posterior_variance[t])\n",
        "    noise = torch.randn_like(values_now, device=DEVICE)\n",
        "    values_one_step_denoised = model_mean + posterior_std_t * noise\n",
        "\n",
        "  # Clone and update with denoised values\n",
        "  denoised_x = g.x.clone()\n",
        "  denoised_x[mask] = values_one_step_denoised.flatten()\n",
        "\n",
        "  return denoised_x\n"
      ],
      "metadata": {
        "id": "oCpdISE2yxMC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z5AegWA7Cy-c"
      },
      "outputs": [],
      "source": [
        "def overwrite_with_noise(g):\n",
        "  g.x_old = g.x.clone()\n",
        "  mask = torch.concat((torch.tensor([False]*g.x_old.shape[0], device=DEVICE).view(-1,1), g.x_old[:,1:]>-0.5), dim=1)\n",
        "  g.x[mask] = torch.randn_like(g.x[mask])\n",
        "  return g\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def generate_examples(model, dataset_train, num=100, restart_inference_method=False):\n",
        "  \"\"\"\n",
        "  Generate graph samples in batches using the provided model.\n",
        "  \"\"\"\n",
        "  # Setup\n",
        "  print(\"generate samples batched\")\n",
        "  model.eval()\n",
        "  dataset_train_start = list()\n",
        "\n",
        "  while len(dataset_train_start) < num:\n",
        "    g = dataset_train[random.choice(range(len(dataset_train)))]\n",
        "    dataset_train_start.append(g.clone().to(DEVICE))\n",
        "\n",
        "  #old\n",
        "  #while len(dataset_train_start) < num:\n",
        "  #  g = dataset_train[random.sample(range(len(dataset_train)),1)[0]]\n",
        "  #  dataset_train_start.append(g.clone().to(DEVICE))\n",
        "  #  g = dataset_train_start[-1]\n",
        "\n",
        "  assert(len(dataset_train_start) == num)\n",
        "  dataloader = DataLoader(dataset_train_start, batch_size=num)\n",
        "\n",
        "  # Inference\n",
        "  for g in dataloader:\n",
        "    g = g.to(DEVICE)\n",
        "    print(\"load g\", g, g.batch)\n",
        "    g = overwrite_with_noise(g)\n",
        "\n",
        "    for i in tqdm(range(TIMESTEPS)):\n",
        "      t = int(TIMESTEPS - i - 1)\n",
        "      if restart_inference_method:\n",
        "        x_with_less_noise = denoise_one_step_restart(model, g, i) #todo\n",
        "      else:\n",
        "        x_with_less_noise = denoise_one_step(model, g, i)\n",
        "      g.x = x_with_less_noise\n",
        "\n",
        "    graph_list = g.to_data_list()\n",
        "    graph_list = [g.cpu() for g in graph_list]\n",
        "\n",
        "    print(\"generated graphs \", graph_list[:10])\n",
        "    return graph_list\n"
      ],
      "metadata": {
        "id": "c8RKX4tVZGy2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3snibPC2C4-f"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def find_frac_correct(graphs):\n",
        "  \"\"\"\n",
        "  Determine the fraction and unique of correct graphs based on their conversion to SMILES.\n",
        "  \"\"\"\n",
        "  correct = 0\n",
        "  smiles_list = list()\n",
        "\n",
        "  for i, g in tqdm(enumerate(graphs)):\n",
        "    smiles = pyg_to_smiles(g)\n",
        "    if smiles and '.' not in smiles:\n",
        "      mol = Chem.MolFromSmiles(smiles)\n",
        "      if mol:\n",
        "        correct += 1\n",
        "        smiles_list.append((smiles, i))\n",
        "\n",
        "  frac_correct = correct / len(graphs)\n",
        "  smiles_list_0 = [s[0] for s in smiles_list]\n",
        "  unique_frac = len(set(smiles_list_0)) / len(graphs)\n",
        "\n",
        "  return frac_correct, smiles_list, unique_frac\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Pm9B-IOqC6j2"
      },
      "outputs": [],
      "source": [
        "def gen_graphs(num_per_generation=1000, num_generations=40, restart_inference_method=False, model_path=None):\n",
        "  \"\"\"\n",
        "  Generate a specified number of graphs.\n",
        "  \"\"\"\n",
        "  if DEBUG:\n",
        "    num_generations = int(num_generations / 10)\n",
        "\n",
        "  if model_path is None:\n",
        "    model_path = PATH_PATTERN + \"_model_epoch_*.pth\"\n",
        "\n",
        "  path = sorted(glob.glob(model_path))[-1]\n",
        "  num_samples = num_per_generation * num_generations\n",
        "  filepath = path.replace(\".pth\", f'_{num_samples:06d}_w{restart_inference_method}_generated.pickle')\n",
        "\n",
        "  results = list()\n",
        "  try:\n",
        "    results = load_file(filepath)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  if len(results) == num_samples:\n",
        "    return results\n",
        "\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  model_base = load_base_model(dataset_base, path_pattern=path)\n",
        "\n",
        "  i = 0\n",
        "  while len(results) < num_samples:\n",
        "    i += 1\n",
        "    num = max(num_per_generation, len(results) - num_samples)\n",
        "    graphs = generate_examples(model_base, dataset_base, num=num, restart_inference_method=restart_inference_method)\n",
        "    results.extend(graphs)\n",
        "    if i % 5 == 0 or len(results) >= num_samples:\n",
        "      write_file(filepath, results)\n",
        "\n",
        "  assert(len(results) == num_samples)\n",
        "  return results\n",
        "\n",
        "\n",
        "def test_graph_generation(path_pattern=None, restart_inference_method=False):\n",
        "  generated_graphs = gen_graphs(restart_inference_method=restart_inference_method, model_path=path_pattern)\n",
        "  return find_frac_correct(generated_graphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBi59QK5C91I"
      },
      "source": [
        "## Discriminator NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LWIOKsKWC_A5"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "\n",
        "class PNAdisc(torch.nn.Module):\n",
        "  def __init__(self, train_dataset=None, hidden_channels=HIDDEN_CHANNELS_DISC,\n",
        "               depth=DEPTH_DISC, dropout=DROPOUT_DISC, towers=1,\n",
        "               normalization=NORMALIZATION_DISC, pre_post_layers=1):\n",
        "    super(PNAdisc, self).__init__()\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Adjust hidden channels based on towers\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "\n",
        "    in_channels = INDICATOR_FEATURE_DIM + ATOM_FEATURE_DIM + BOND_FEATURE_DIM\n",
        "    assert in_channels == 11\n",
        "\n",
        "    deg = dataset_to_degree_bin(train_dataset).to(DEVICE)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
        "    self.pnanet = PNA(in_channels=in_channels,\n",
        "                     hidden_channels=hidden_channels,\n",
        "                     out_channels=1,\n",
        "                     num_layers=depth,\n",
        "                     aggregators=aggregators,\n",
        "                     scalers=scalers,\n",
        "                     deg=deg,\n",
        "                     dropout=dropout,\n",
        "                     towers=towers,\n",
        "                     norm=self.normalization,\n",
        "                     pre_layers=pre_post_layers,\n",
        "                     post_layers=pre_post_layers)\n",
        "\n",
        "  def forward(self, x, edge_index, batch=None):\n",
        "    x = x + torch.randn_like(x) * DISC_NOISE\n",
        "    x = self.pnanet(x, edge_index)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gh-x4OlODFBX"
      },
      "outputs": [],
      "source": [
        "def train_epoch_disc(model_disc, dataloader, optimizer):\n",
        "  model_disc.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = []\n",
        "  acc_list = []\n",
        "\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    acc = (torch.abs(pred.flatten() - batch.y.flatten()) < 0.5).float()\n",
        "    acc_list.extend(acc.detach().cpu().tolist())\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gCnHC3mPDGoM"
      },
      "outputs": [],
      "source": [
        "def test_disc(model_disc, dataloader):\n",
        "  model_disc.eval()\n",
        "  start_time = time.time()\n",
        "  loss_list = list()\n",
        "  acc_list = list()\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(DEVICE)\n",
        "    pred = model_disc(batch.x, batch.edge_index, batch.batch)\n",
        "    loss = F.binary_cross_entropy(pred.flatten(), batch.y.flatten())\n",
        "    acc = (torch.abs(pred.flatten()-batch.y.flatten()) < 0.5).float()\n",
        "    acc_list = acc_list + acc.detach().cpu().tolist()\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "  return np.mean(loss_list), np.mean(acc_list), time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_disc_model(dataloader_disc, dataloader_disc_test, round_i):\n",
        "  model_disc = PNAdisc(dataloader_disc).to(DEVICE)\n",
        "  weight_path = f\"discriminator_model_{round_i:05}.pth\"\n",
        "\n",
        "  try:\n",
        "    checkpoint = torch.load(weight_path)\n",
        "    model_disc.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"found disc model in round {round_i:05}\")\n",
        "    return model_disc\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  epochs = []\n",
        "  losses_train = []\n",
        "  losses_test = []\n",
        "\n",
        "  optimizer_disc = Adam(model_disc.parameters(), lr=0.0001)\n",
        "  for epoch_i in range(EPOCHS_DISC_MODEL):\n",
        "    loss_train, acc_train, t_train = train_epoch_disc(model_disc, dataloader_disc, optimizer_disc)\n",
        "    if epoch_i % 10 == 1 or epoch_i == EPOCHS_DISC_MODEL - 1:\n",
        "      loss_test, acc_test, t_test = test_disc(model_disc, dataloader_disc_test)\n",
        "      print(f\"train discriminator: epoch: {epoch_i:05}, loss: {loss_train:.4f}, loss test: {loss_test:.4f}, acc: {acc_train:.3f}, acc test: {acc_test:.3f}, time: {t_train:.3f}\")\n",
        "      log({\n",
        "          \"disc/step\": epoch_i,\n",
        "          \"disc/epoch\": epoch_i,\n",
        "          \"disc/loss_train\": loss_train,\n",
        "          'disc/loss_test': loss_test,\n",
        "          \"disc/acc_train\": acc_train,\n",
        "          \"disc/acc_test\": acc_test,\n",
        "          \"disc/time\": t_train\n",
        "      })\n",
        "      epochs.append(epoch_i)\n",
        "      losses_train.append(loss_train)\n",
        "      losses_test.append(loss_test)\n",
        "\n",
        "  # Plotting losses\n",
        "  plt.clf()\n",
        "  plt.plot(epochs, losses_train, label='train')\n",
        "  plt.plot(epochs, losses_test, label='test')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"discriminator_model_{round_i:05}.png\")\n",
        "\n",
        "  torch.save({\n",
        "      'model_state_dict': model_disc.state_dict(),\n",
        "      'epochs': epochs,\n",
        "      \"losses_train\": losses_train,\n",
        "      \"losses_test\": losses_test\n",
        "  }, weight_path)\n",
        "\n",
        "  return model_disc\n"
      ],
      "metadata": {
        "id": "b6vWTeUicmzH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XF6Sq0OsDLHt"
      },
      "outputs": [],
      "source": [
        "def run_disc(round_i=1):\n",
        "  fake_graphs = gen_graphs(restart_inference_method=False)\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  real_graphs = random.sample(dataset_base, len(fake_graphs))\n",
        "  dataset = list()\n",
        "\n",
        "  for g in fake_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(0.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  for g in real_graphs:\n",
        "    g_i = g.clone()\n",
        "    g_i.y = torch.tensor(1.0)\n",
        "    dataset.append(g_i)\n",
        "\n",
        "  random.shuffle(dataset)\n",
        "  cut_off = int(len(dataset) * 0.8)\n",
        "  dataloader_train = DataLoader(dataset[:cut_off], batch_size = BATCH_SIZE, shuffle=True)\n",
        "  dataloader_test = DataLoader(dataset[cut_off:], batch_size = BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  model_disc = train_disc_model(dataloader_train, dataloader_test, round_i)\n",
        "  return model_disc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAVWEgfDDkcM"
      },
      "source": [
        "## Train Jointly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, optimizer, model_disc=None):\n",
        "  schedule = generate_schedule()\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  loss_list = []\n",
        "  loss_list_start = []\n",
        "\n",
        "  for batch in tqdm(dataloader):\n",
        "    if batch.x.shape[0] < 2:\n",
        "      continue\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = batch.to(DEVICE)\n",
        "    row_num = batch.x.shape[0]\n",
        "\n",
        "    num_graphs_in_batch = int(torch.max(batch.batch).item() + 1)\n",
        "    future_t_select = torch.randint(0, TIMESTEPS, (num_graphs_in_batch,), device=DEVICE)\n",
        "    future_t = torch.gather(future_t_select, 0, batch.batch)\n",
        "    assert future_t.numel() == row_num\n",
        "\n",
        "    mask = torch.cat((torch.tensor([False] * row_num, device=DEVICE).view(-1, 1), batch.x[:, 1:] > -0.5), dim=1)\n",
        "    x_start_gt = batch.x[mask].view(row_num, FEATURE_DIM)\n",
        "    x_with_noise, noise_gt = forward_diffusion(x_start_gt, future_t)\n",
        "\n",
        "    x_in = batch.x.clone()\n",
        "    x_in[mask] = x_with_noise.flatten()\n",
        "    x_start_pred = model(x_in, future_t, batch.edge_index)\n",
        "    loss = F.mse_loss(x_start_gt, x_start_pred)\n",
        "\n",
        "    disc_loss = torch.tensor(0.0, device=DEVICE)\n",
        "    if model_disc is not None:\n",
        "      x_in[mask] = x_start_pred.flatten()\n",
        "      disc_loss = torch.mean((1.0 - model_disc(x_in, batch.edge_index, batch=batch.batch))**2)\n",
        "      loss = (1.0 - GAMMA) * loss + GAMMA * disc_loss\n",
        "\n",
        "    loss.backward()\n",
        "    loss_list.append(loss.item())\n",
        "    loss_list_start.append(disc_loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "  return np.mean(loss_list), np.mean(loss_list_start), time.time() - start_time\n"
      ],
      "metadata": {
        "id": "vSqf7G3GfIi8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_base_model(train_loader, epoch_num=EPOCHS_GEN, model_disc=None):\n",
        "  print(\"train base model\")\n",
        "  if DEBUG:\n",
        "    epoch_num = int(epoch_num / 10)\n",
        "\n",
        "  dataset_train = train_loader.dataset\n",
        "  model_base = PNAnet(dataset_train).to(DEVICE)\n",
        "\n",
        "  optimizer = Adam(model_base.parameters(), lr=LEARNING_RATE_GEN * 0.01) # the mutliplication makes no real sense\n",
        "  loss_list = []\n",
        "  model_base, optimizer, loss_list, epoch_start = load_latest_checkpoint(model_base, optimizer, loss_list, epoch_i=0)\n",
        "  epoch_start = min(epoch_start, epoch_num)\n",
        "  print(f\"from {epoch_start} to {epoch_num}\")\n",
        "\n",
        "  for epoch_i in range(epoch_start, epoch_num):\n",
        "    try:\n",
        "      loss, loss_start, time_elapsed = train_epoch(model_base, train_loader, optimizer, model_disc=model_disc)\n",
        "      loss_list.append((epoch_i, loss))\n",
        "      mean_loss = np.mean([y for _, y in loss_list] + [loss])\n",
        "      print(f\"loss in epoch {epoch_i:07} is: {loss:05.4f} with mean loss {mean_loss:05.4f} with start loss {loss_start:05.4f} with runtime {time_elapsed:05.4f}\")\n",
        "      log({\n",
        "        \"gen/step\": epoch_i,\n",
        "        \"gen/epoch\": epoch_i,\n",
        "        \"gen/loss\": loss,\n",
        "        \"gen/mean_loss\": mean_loss,\n",
        "        \"gen/start_loss\": loss_start,\n",
        "        \"gen/runtime\": time_elapsed\n",
        "      })\n",
        "\n",
        "      if (epoch_i % 20 == 0 and epoch_i > epoch_start) or epoch_i == epoch_num - 1 or BATCH_SIZE == 1:\n",
        "        print(\"save\")\n",
        "        save_model(model_base, optimizer, loss_list, epoch_i + 1, upload = epoch_i == epoch_num - 1)\n",
        "        time.sleep(0.01)\n",
        "        frac, smiles_list, unique_frac = test_graph_generation(restart_inference_method=False)\n",
        "        frac_restart, smiles_list_restart, unique_frac_restart = 0, 0, 0 #test_graph_generation(restart_inference_method=True)\n",
        "        print(f\"Fraction of correct graphs: {frac}, with restart_inference_method inference {frac_restart}\")\n",
        "        log({\n",
        "          \"inference/step\": epoch_i,\n",
        "          \"inference/epoch\": epoch_i,\n",
        "          \"inference/frac_normal\": frac,\n",
        "          \"inference/frac_restart\": frac_restart,\n",
        "          \"inference/frac_normal_unique\": unique_frac,\n",
        "          \"inference/frac_restart_unique\": unique_frac_restart\n",
        "        })\n",
        "        log_smiles(smiles_list, f\"{PATH_PATTERN}_smiles_{epoch_i}_normal.txt\")\n",
        "        log_smiles(smiles_list_restart, f\"{PATH_PATTERN}_smiles_{epoch_i}_restart.txt\")\n",
        "        try:\n",
        "          print(smiles_list[:20])\n",
        "          print(smiles_list_restart[:20])\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "    except Exception as e:\n",
        "      print(f\"An error occurred during training: \\n{str(e)}\")\n",
        "      traceback.print_exc()\n",
        "      raise e\n",
        "\n",
        "  return model_base\n"
      ],
      "metadata": {
        "id": "5hRd_XXGgkRS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qbC0Wq8D5Ux"
      },
      "source": [
        "### Putting Everything Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Q6zFANMID6j-"
      },
      "outputs": [],
      "source": [
        "def start_experiments(rounds=6): #originally 5\n",
        "  global DISC_NOISE\n",
        "  dataset_base, dataset_base_test = build_dataset()\n",
        "  dataloader_base = DataLoader(dataset_base, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  model_base = train_base_model(dataloader_base, epoch_num = EPOCHS_GEN*1)\n",
        "\n",
        "  for round_i in range(1, rounds):\n",
        "    if BASELINE:\n",
        "      model_disc = None\n",
        "    else:\n",
        "      model_disc = run_disc(round_i=round_i)\n",
        "    model_base = train_base_model(dataloader_base, epoch_num = EPOCHS_GEN*(round_i+1), model_disc=model_disc)\n",
        "\n",
        "  save_src_file()\n",
        "  return  model_base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_OiyFytEAKd"
      },
      "source": [
        "### Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "H2haryq1EA_m"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import wandb\n",
        "except:\n",
        "  # Train with discriminator (our method)\n",
        "  start_experiments(rounds=5)\n",
        "  # Train without discriminator (baseline)\n",
        "  BASELINE = True\n",
        "  start_experiments(rounds=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "086_7Od-EVX1"
      },
      "source": [
        "## Training with WandB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7ZWyjSb0d_8"
      },
      "source": [
        "We can use WandB to save the training results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "f5SWqlSfEWSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a269de2f-f990-4828-ee04-6d71f82f22cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/usr/local/lib/python3.10/dist-packages/wandb']\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "print(wandb.__path__) # this should look like ['/usr/local/lib/python3.10/dist-packages/wandb']. Make sure to not install wandb into your current working dir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lFyzrxmZFAMJ"
      },
      "outputs": [],
      "source": [
        "WANDB_TOKEN = \"\" # Add you WandB token here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "M3MHvxtkEYW2"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"name\": \"AliaMol\",\n",
        "    \"method\": \"random\",\n",
        "    \"metric\": {\n",
        "        \"name\": \"ENZYMES/besttest_acc\",\n",
        "        \"goal\": \"maximize\",\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"BATCH_SIZE\": {\"values\": [256]},\n",
        "        \"GAMMA\": {\"values\": [0.1]},\n",
        "        \"DISC_NOISE\": {\"values\": [0.03]}, # original 0.05\n",
        "        \"EPOCHS_DISC_MODEL\": {\"values\": [60]}, # original 100\n",
        "        \"EPOCHS_GEN\": {\"values\": [60]}, # original 0.05\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ivM55NJ7EeuR"
      },
      "outputs": [],
      "source": [
        "def save_src_file():\n",
        "  try:\n",
        "    os.system(\"pip list > pip_list.txt 2>&1\")\n",
        "    for txt_file in sorted(glob.glob('*.txt')):\n",
        "      z = \"\".join(filter(str.isalnum, txt_file))\n",
        "      wandb.log_artifact(txt_file, name=f\"src_txt_{SWEEP_ID}_{z}\", type=\"my_dataset_txt\")\n",
        "    for python_file in sorted(glob.glob('*.ipynb')):\n",
        "      z = \"\".join(filter(str.isalnum, python_file))\n",
        "      wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}_{z}\", type=\"my_dataset_ipynb\")\n",
        "    for python_file in sorted(glob.glob('*.py')):\n",
        "      z = \"\".join(filter(str.isalnum, python_file))\n",
        "      wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}_{z}\", type=\"my_dataset_py\")\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TNLB7QwoEgy9"
      },
      "outputs": [],
      "source": [
        "def get_wand_api_key():\n",
        "  global WANDB_TOKEN\n",
        "  if len(WANDB_TOKEN) > 0:\n",
        "    return WANDB_TOKEN\n",
        "  import sys\n",
        "  IN_COLAB = 'google.colab' in sys.modules\n",
        "  if not IN_COLAB:\n",
        "    os.system(\"cp ~/api_key.txt api_key.txt\")\n",
        "  file_path = 'api_key.txt'\n",
        "  with open(file_path, 'r') as file:\n",
        "      api_key = file.read().strip()\n",
        "  return api_key\n",
        "\n",
        "\n",
        "def main():\n",
        "  global PATH_PATTERN\n",
        "  with wandb.init() as run:\n",
        "    PATH_PATTERN = PATH_PATTERN_BASE + '_' +str(run.name) + '_' +str(BASELINE)\n",
        "    save_src_file()\n",
        "    for hyper_param_name in sweep_config['parameters']:\n",
        "      globals()[hyper_param_name] = run.config[hyper_param_name]\n",
        "      print(\"set \", hyper_param_name, \"=\", run.config[hyper_param_name])\n",
        "    start_experiments()\n",
        "    write_file(\"runs.pickle\", run.name)\n",
        "\n",
        "def start_with_wandb(set_baseline_true=False):\n",
        "  import wandb\n",
        "  global SWEEP_ID, USE_WANDB, PATH_PATTERN, BASELINE\n",
        "  if set_baseline_true:\n",
        "    BASELINE = True\n",
        "  else:\n",
        "    BASELINE = False\n",
        "  USE_WANDB = True\n",
        "  os.environ[\"WANDB_MODE\"] = \"online\"\n",
        "  try:\n",
        "    SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
        "    wandb.agent(SWEEP_ID, function=main, count=5)\n",
        "  except Exception as e:\n",
        "    error_message = traceback.format_exc()\n",
        "    print(\"final error:\\n\", error_message)\n",
        "    with open('_error_log.txt', 'a') as f:\n",
        "      f.write(error_message + '\\n')\n",
        "    time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_with_wandb()\n",
        "start_with_wandb(set_baseline_true=True)"
      ],
      "metadata": {
        "id": "eaHcCeD0Dpgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8/zfesrKOFm8icGccBzZa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}